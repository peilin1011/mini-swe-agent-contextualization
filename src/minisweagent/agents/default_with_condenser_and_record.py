"""Agent with workflow-based message summarization and compression.

This agent extends DefaultAgent with intelligent message compression:
- Keeps first N messages (system prompt, task description, etc.)
- Keeps last M rounds per completed sub-task
- Keeps all messages for current task
- Summarizes and compresses intermediate messages using a summary model
"""

import json
import os
import re
import subprocess
import traceback
from collections.abc import Callable
from dataclasses import asdict, dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any

from jinja2 import StrictUndefined, Template

from minisweagent import Environment, Model
from minisweagent.utils.log import logger


@dataclass
class AgentConfig:
    """Configuration for agent with workflow compression."""
    system_template: str = "You are a helpful assistant that can do anything."
    instance_template: str = (
        "Your task: {{task}}. Please reply with a single shell command in triple backticks. "
        "To finish, the first line of the output of the shell command must be 'COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT'."
    )
    timeout_template: str = (
        "The last command <command>{{action['action']}}</command> timed out and has been killed.\n"
        "The output of the command was:\n <output>\n{{output}}\n</output>\n"
        "Please try another command and make sure to avoid those requiring interactive input."
    )
    format_error_template: str = "Please always provide EXACTLY ONE action in triple backticks."
    action_observation_template: str = "Observation: {{output}}"
    step_limit: int = 0
    cost_limit: float = 3.0
    
    # Workflow compression settings
    enable_condenser: bool = True
    keep_first: int = 4
    keep_last_round_per_task: int = 1
    condenser_template: str = ""
    summary_model: dict[str, Any] | None = field(default_factory=lambda: None)
    instance_name: str = ""
    
    # Compression logging settings
    enable_compression_logging: bool = True
    compression_log_dir: str = "compression_logs"


class NonTerminatingException(Exception):
    """Raised for conditions that can be handled by the agent."""


class FormatError(NonTerminatingException):
    """Raised when the LM's output is not in the expected format."""


class ExecutionTimeoutError(NonTerminatingException):
    """Raised when the action execution timed out."""


class TerminatingException(Exception):
    """Raised for conditions that terminate the agent."""


class Submitted(TerminatingException):
    """Raised when the LM declares that the agent has finished its task."""


class LimitsExceeded(TerminatingException):
    """Raised when the agent has reached its cost or step limit."""


class DefaultAgent:
    def __init__(self, model: Model, env: Environment, *, config_class: Callable = AgentConfig, **kwargs):
        self.config = config_class(**kwargs)
        self.model = model
        self.env = env
        self.messages = []
        self.summary_model = None
        
        # æ·»åŠ summary modelç»Ÿè®¡è·Ÿè¸ª
        self.summary_model_cost = 0.0
        self.summary_model_calls = 0

        # åˆå§‹åŒ–å‹ç¼©æ—¥å¿—ç›®å½•ï¼ˆå¦‚æœå¯ç”¨è®°å½•ï¼‰
        if self.config.enable_compression_logging:
            self.compression_log_dir = Path(self.config.compression_log_dir)
            self.compression_log_dir.mkdir(exist_ok=True)
            
            # ä¸ºæ¯ä¸ªinstanceåˆ›å»ºæ—¥å¿—æ–‡ä»¶
            if self.config.instance_name:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                self.compression_log_file = self.compression_log_dir / f"{self.config.instance_name}_{timestamp}.jsonl"
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                self.compression_log_file = self.compression_log_dir / f"compression_{timestamp}.jsonl"
        else:
            self.compression_log_dir = None
            self.compression_log_file = None

        # åªåœ¨å¯ç”¨ condenser æ—¶æ‰åˆå§‹åŒ–æ€»ç»“æ¨¡å‹
        if not self.config.enable_condenser:
            logger.info("â„¹ï¸  å·¥ä½œæµç¨‹å‹ç¼©åŠŸèƒ½å·²ç¦ç”¨ (enable_condenser=False)")
            return

        # åˆå§‹åŒ–æœ¬åœ°æ€»ç»“æ¨¡å‹ - ä»configçš„summary_modelèŠ‚ç‚¹è¯»å–é…ç½®
        if self.config.summary_model and self.config.summary_model.get("model_name"):
            try:
                from minisweagent.models import get_model

                summary_model_config = {
                    "model_name": self.config.summary_model["model_name"],
                    "model_kwargs": {
                        "api_base": self.config.summary_model.get("api_base", ""),
                        "api_key": self.config.summary_model.get("api_key", ""),
                        "temperature": 0.0,
                        "drop_params": True,
                    }
                }

                self.summary_model = get_model(
                    self.config.summary_model["model_name"],
                    config=summary_model_config
                )
                logger.info("âœ… å·¥ä½œæµç¨‹å‹ç¼©åŠŸèƒ½å·²å¯ç”¨")
                logger.info(f"   æ€»ç»“æ¨¡å‹: {self.config.summary_model['model_name']}")
            except Exception as e:
                logger.error(f"âš ï¸ æ€»ç»“æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œå‹ç¼©åŠŸèƒ½å°†è¢«ç¦ç”¨: {e}")
                import traceback
                traceback.print_exc()
                self.summary_model = None
        else:
            logger.warning("âš ï¸ enable_condenser=True ä½†æœªé…ç½® summary_model.model_nameï¼Œå‹ç¼©åŠŸèƒ½å°†è¢«ç¦ç”¨")

    def render_template(self, template: str, **kwargs) -> str:
        template_vars = asdict(self.config) | self.env.get_template_vars() | self.model.get_template_vars()
        return Template(template, undefined=StrictUndefined).render(
            **kwargs, **template_vars, **self.extra_template_vars
        )

    def _log_compression_interaction(self, input_conversation: str, output_summary: str, 
                                   model_name: str, step_count: int, message_count: int):
        """è®°å½•å‹ç¼©LLMçš„è¾“å…¥è¾“å‡ºäº¤äº’"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å‹ç¼©æ—¥å¿—è®°å½•
        if not self.config.enable_compression_logging or not self.compression_log_file:
            return
            
        try:
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "step_count": step_count,
                "message_count": message_count,
                "model_name": model_name,
                "input": input_conversation,  # å®Œæ•´çš„å¯¹è¯æ–‡æœ¬å­—ç¬¦ä¸²
                "output": output_summary,  # å‹ç¼©ç”Ÿæˆçš„summary
                "instance_name": self.config.instance_name,
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                "summary_model_calls": self.summary_model_calls,
                "summary_model_cost": self.summary_model_cost,
                "main_model_calls": getattr(self.model, 'n_calls', 0),
                "main_model_cost": getattr(self.model, 'cost', 0.0)
            }
            
            # è¿½åŠ åˆ°JSONLæ–‡ä»¶
            with open(self.compression_log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
                
            logger.debug(f"ğŸ“ å‹ç¼©äº¤äº’å·²è®°å½•åˆ°: {self.compression_log_file}")
            logger.debug(f"ğŸ“Š æœ¬æ¬¡è®°å½•åŒ…å«ç»Ÿè®¡: {self.summary_model_calls} æ¬¡è°ƒç”¨, ${self.summary_model_cost:.4f} èŠ±è´¹")
            
        except Exception as e:
            logger.error(f"âš ï¸ å‹ç¼©æ—¥å¿—è®°å½•å¤±è´¥: {e}")

    def _should_condense_and_compress(self) -> bool:
        """ä½¿ç”¨æ€»ç»“æ¨¡å‹ä¸€æ­¥å®Œæˆåˆ¤æ–­å’Œå‹ç¼© - å¦‚æœå®Œæˆsubtaskå°±ç”¨condenser_templateæ€»ç»“ï¼Œå¦åˆ™skip"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å‹ç¼©åŠŸèƒ½
        if not self.config.enable_condenser or not self.summary_model:
            return False
        
        # åˆ†æå…¨éƒ¨ä¸Šä¸‹æ–‡æ¶ˆæ¯
        messages_to_analyze = self.messages
        # åªéœ€è¦ä¸€æ¬¡æ£€æŸ¥ï¼šè‡³å°‘éœ€è¦å‰2æ¡+keep_first
        min_messages_needed = 2 + self.config.keep_first
        if len(messages_to_analyze) < min_messages_needed:
            return False
        
        # æ„å»ºè¦åˆ†æçš„å¯¹è¯æ–‡æœ¬
        conversation_text = ""
        for i, msg in enumerate(messages_to_analyze):
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            if len(content) > 40000:
                content = content[:40000] + "..."
            conversation_text += f"[Message {i}] {role}:\n{content}\n\n"
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº† condenser_template
        if not self.config.condenser_template:
            logger.debug("âš ï¸ æœªé…ç½® condenser_templateï¼Œè·³è¿‡å‹ç¼©")
            return False

        # ä½¿ç”¨æ€»ç»“æ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©å¹¶ç”Ÿæˆæ€»ç»“
        condenser_prompt = self.render_template(self.config.condenser_template, conversation_text=conversation_text)

        try:
            analysis_messages = [{"role": "user", "content": condenser_prompt}]
            response = self.summary_model.query(analysis_messages)
            response_content = response.get("content", "").strip()

            if "NO_COMPRESSION_NEEDED" in response_content.upper():
                logger.debug(f"ğŸ¤– {self.config.summary_model['model_name']}: æš‚ä¸å‹ç¼© - æœªæ‰¾åˆ°å·²å®Œæˆçš„å­ä»»åŠ¡")
                logger.debug(f"ğŸ“Š Summaryæ¨¡å‹ç»Ÿè®¡: {self.summary_model_calls} æ¬¡å‹ç¼©, ${self.summary_model_cost:.4f} èŠ±è´¹")
                return False

            # åªæœ‰åœ¨å®é™…å‹ç¼©æ—¶æ‰è®°å½•ç»Ÿè®¡
            self.summary_model_calls += 1
            # è®¡ç®—æœ¬æ¬¡è°ƒç”¨çš„æˆæœ¬ï¼ˆå½“å‰æ€»æˆæœ¬ - ä¹‹å‰çš„æ€»æˆæœ¬ï¼‰
            current_total_cost = self.summary_model.cost
            previous_total_cost = self.summary_model_cost
            self.summary_model_cost = current_total_cost

            # åªæœ‰åœ¨å®é™…å‹ç¼©æ—¶æ‰è®°å½•æ—¥å¿—
            logger.info(f"ğŸ¤– {self.config.summary_model['model_name']}: éœ€è¦å‹ç¼© - æ‰¾åˆ°å·²å®Œæˆçš„å­ä»»åŠ¡")
            logger.info(f"ğŸ“Š Summaryæ¨¡å‹ç»Ÿè®¡: {self.summary_model_calls} æ¬¡å‹ç¼©, ${self.summary_model_cost:.4f} èŠ±è´¹")
            logger.debug(f"ğŸ“ æ€»ç»“å†…å®¹é¢„è§ˆ: {response_content[:1000]}...")

            # è®°å½•å‹ç¼©LLMçš„è¾“å…¥è¾“å‡º
            step_count = getattr(self.model, 'n_calls', 0)
            self._log_compression_interaction(
                input_conversation=conversation_text,  # å®Œæ•´çš„å¯¹è¯æ–‡æœ¬å­—ç¬¦ä¸²
                output_summary=response_content,  # å‹ç¼©ç”Ÿæˆçš„summary
                model_name=self.config.summary_model['model_name'],
                step_count=step_count,
                message_count=len(self.messages)
            )

            # æ‰§è¡Œå‹ç¼©ï¼Œä½¿ç”¨æ¨¡å‹è¿”å›çš„æ€»ç»“
            return self._execute_compression_with_summary(response_content)

        except Exception as e:
            logger.error(f"âš ï¸ {self.config.summary_model['model_name']} å‹ç¼©å¤±è´¥: {e}")
            traceback.print_exc()
            return False

    def _execute_compression_with_summary(self, summary: str) -> bool:
        """æ‰§è¡Œæ¶ˆæ¯å‹ç¼©ï¼Œå°†summaryæ’å…¥åˆ°æŒ‡å®šä½ç½®"""
        try:
            # 1. ä¿ç•™å‰2æ¡ï¼šsystem instruction + user PR
            keep_first_two = self.messages[:2]
            
            # 2. è®¡ç®—è¦ä¿ç•™çš„æœ€åå‡ è½®å¯¹è¯
            messages_after_pr = self.messages[2:]  # system + user PR ä¹‹åçš„æ‰€æœ‰æ¶ˆæ¯
            
            # 3. è®¡ç®—æœ€åå‡ è½®å¯¹è¯
            if self.config.keep_last_round_per_task > 0:
                rounds_to_keep = self.config.keep_last_round_per_task * 2
                last_rounds = messages_after_pr[-rounds_to_keep:]
            else:
                last_rounds = []
            
            # 4. åˆ›å»ºæ€»ç»“æ¶ˆæ¯
            summary_msg = {
                "role": "user",
                "content": f"[Previous work summary]\n{summary}"
            }
            
            # 5. é‡å»ºæ¶ˆæ¯åˆ—è¡¨ï¼šå‰2æ¡ + summary + æœ€åå‡ è½®å¯¹è¯
            original_count = len(self.messages)
            self.messages = keep_first_two + [summary_msg] + last_rounds
            new_count = len(self.messages)
            
            logger.info(f"ğŸ”„ [å·¥ä½œæµç¨‹å‹ç¼©] æ‰§è¡Œå‹ç¼©: {original_count} æ¡æ¶ˆæ¯")
            logger.info(f"âœ… [å·¥ä½œæµç¨‹å‹ç¼©] å®Œæˆ: {original_count} â†’ {new_count} æ¡æ¶ˆæ¯")
            logger.info(f"ğŸ“Š å‹ç¼©åæ¶ˆæ¯æ•°é‡: {new_count}")
            logger.info(f"ğŸ“‹ ä¿ç•™ç»“æ„: å‰2æ¡ + æ€»ç»“ + æœ€å{self.config.keep_last_round_per_task}è½®")
            
            return True
            
        except Exception as e:
            logger.error(f"âš ï¸ å‹ç¼©æ‰§è¡Œå¤±è´¥: {e}")
            traceback.print_exc()
            return False

    def add_message(self, role: str, content: str, **kwargs):
        self.messages.append({"role": role, "content": content, **kwargs})
        
        # ä½¿ç”¨ debug çº§åˆ«ï¼Œåªå†™æ–‡ä»¶ï¼Œä¸æ˜¾ç¤ºåœ¨ç»ˆç«¯
        logger.info(f"[MESSAGE] Role: {role.upper()}")
        logger.info(f"[CONTENT] {content}")
        logger.info("-" * 80)

    def run(self, task: str, **kwargs) -> tuple[str, str]:
        """Run step() until agent is finished. Return exit status & message"""
        self.extra_template_vars = {"task": task, **kwargs}
        self.messages = []
        self.add_message("system", self.render_template(self.config.system_template))
        self.add_message("user", self.render_template(self.config.instance_template))
        while True:
            try:
                self.step()
            except NonTerminatingException as e:
                self.add_message("user", str(e))
            except TerminatingException as e:
                self.add_message("user", str(e))
                return type(e).__name__, str(e)

    def step(self) -> dict:
        """Query the LM, execute the action, return the observation."""
        # åœ¨æ¯æ­¥ä¹‹å‰æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
        if self.config.enable_condenser and self.summary_model:
            self._should_condense_and_compress()
        
        return self.get_observation(self.query())

    def query(self) -> dict:
        """Query the model and return the response."""
        if 0 < self.config.step_limit <= self.model.n_calls or 0 < self.config.cost_limit <= self.model.cost:
            raise LimitsExceeded()
        response = self.model.query(self.messages)
        self.add_message("assistant", **response)
        return response

    def get_observation(self, response: dict) -> dict:
        """Execute the action and return the observation."""
        output = self.execute_action(self.parse_action(response))
        observation = self.render_template(self.config.action_observation_template, output=output)
        self.add_message("user", observation)
        return output

    def parse_action(self, response: dict) -> dict:
        """Parse the action from the message. Returns the action."""
        actions = re.findall(r"```bash\n(.*?)\n```", response["content"], re.DOTALL)
        if len(actions) == 1:
            return {"action": actions[0].strip(), **response}
        raise FormatError(self.render_template(self.config.format_error_template, actions=actions))

    def execute_action(self, action: dict) -> dict:
        try:
            output = self.env.execute(action["action"])
        except subprocess.TimeoutExpired as e:
            output = e.output.decode("utf-8", errors="replace") if e.output else ""
            raise ExecutionTimeoutError(
                self.render_template(self.config.timeout_template, action=action, output=output)
            )
        except TimeoutError:
            raise ExecutionTimeoutError(self.render_template(self.config.timeout_template, action=action, output=""))
        self.has_finished(output)
        return output

    def has_finished(self, output: dict[str, str]):
        """Raises Submitted exception with final output if the agent has finished its task."""
        lines = output.get("output", "").lstrip().splitlines(keepends=True)
        if lines and lines[0].strip() in ["MINI_SWE_AGENT_FINAL_OUTPUT", "COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT"]:
            raise Submitted("".join(lines[1:]))

    def get_summary_model_stats(self) -> dict[str, Any]:
        """è·å–summary modelçš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆåªè®¡ç®—å®é™…å‹ç¼©çš„æ¬¡æ•°ï¼‰"""
        return {
            "summary_model_calls": self.summary_model_calls,
            "summary_model_cost": self.summary_model_cost,
            "summary_model_name": self.config.summary_model.get("model_name", "") if self.config.summary_model else "",
        }
