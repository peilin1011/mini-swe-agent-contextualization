{
    "Qwen3-4B-Instruct-2507": {
      "max_tokens": 8192,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "supports_system_messages": true
    },
    "qwen3-4b": {
      "max_tokens": 8192,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "api_base": "http://localhost:8000/v1",
      "api_key": "EMPTY",
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "supports_system_messages": true
    },
    "Qwen2.5-Coder-32B-Instruct": {
      "max_tokens": 8192,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "supports_system_messages": true
    },
    "gpt-5": {
      "max_tokens": 128000,
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 1.25e-06,
      "output_cost_per_token": 1e-05,
      "cache_read_input_token_cost": 1.25e-07,
      "litellm_provider": "openai",
      "mode": "chat",
      "supported_endpoints": [
        "/v1/chat/completions",
        "/v1/batch",
        "/v1/responses"
      ],
      "supported_modalities": [
        "text",
        "image"
      ],
      "supported_output_modalities": [
        "text"
      ],
      "supports_pdf_input": true,
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_response_schema": true,
      "supports_vision": true,
      "supports_prompt_caching": true,
      "supports_system_messages": true,
      "supports_tool_choice": true,
      "supports_native_streaming": true,
      "supports_reasoning": true
    },
    "Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "max_tokens": 8192,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "api_base": "http://localhost:8000/v1",
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "supports_system_messages": true
    },
    "Qwen/Qwen3-32B": {
      "max_tokens": 8192,
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.01,
      "output_cost_per_token": 0.01,
      "litellm_provider": "openai",
      "api_base": "http://localhost:8000/v1",
      "api_key": "EMPTY",
      "mode": "chat",
      "supports_function_calling": false,
      "supports_parallel_function_calling": false,
      "supports_vision": false,
      "supports_system_messages": true
    }
  }